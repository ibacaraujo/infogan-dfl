# Notes on Chapter 1.6 from Pattern Recognition and Machine Learning / Bishop

We begin to study Information Theory with a discrete random variable and a question about it.

*x* is our discrete random variable and the question is how much information is received when we observe a specific value for this variable.

The amount of information can be thought as the degree of surprise on learning the value of x.

The less probable an event in the value of x is, higher is the information received. That is the measure of information.
