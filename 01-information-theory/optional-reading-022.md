# Notes on mutual information

The relative entropy is the Kullback-Leibler distance. It measures the distance between two probability distributions.

TODO: to add more notes
